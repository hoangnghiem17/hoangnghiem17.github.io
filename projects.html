---
layout: page
title: Projects
permalink: /projects/
excerpt: This page showcases technical projects I worked on during my free time and university.
---

<section class="projects">

  <h2>Table of Contents</h2>
  <ul>
    <li><a href="#master-thesis">Master Thesis</a></li>
    <li><a href="#data-mining-cup">Data Mining Cup</a></li>
    <li><a href="#bert-finetuning">LLM Finetuning</a></li>
  </ul>

  <div class="project-item" id="master-thesis">
    <h3>üéì Master Thesis: Development of chatbots for waste disposal</h3>
    <div class="project-links">
      <a href="https://drive.google.com/file/d/1ylVgv8N6SQ6132dMA7rWG6uSU2ulNdHp/view?usp=drive_link" target="_blank" class="project-link">üìÑ Master Thesis</a>
      <a href="https://github.com/hoangnghiem17/WasteSeparationChatbotLLM.git" target="_blank" class="project-link">üìÅ GitHub</a>
    </div>
    <p><strong>Description:</strong> In my master thesis, I developed a chatbot with 3 different chatbot environments that can assist citizens in sustainable waste disposal. I used Google Dialogflow, Rasa AI and a custom LLM-based implementation (GPT-4o-mini via LangChain and LangGraph). I evaluated the development environments to determine in which use cases they are best suited.</p>
    <p><strong>Skills:</strong></p>
    <ul>
      <li><strong>Concepts:</strong> Agent | LLM | RAG | NLU | NLP | Software Design
      <li><strong>Development:</strong> Python | JavaScript | HTML | CSS  </li></li>
      <li><strong>Skills:</strong> Research | Presentation | Self Management</li>
      <li><strong>Domain:</strong> Sustainability | Waste Management | Public Service</li>
    </ul>
    <p><strong>Key Learnings:</strong> There is a use case for every tool. The choice of the development environment for a waste disposal chatbot depends on the required chatbot features and capabilities of the implementing organization. LLM-based chatbots enable powerful features but requires expertise and effort to implement and maintain.</p>
  </div>

  <div class="project-item" id="data-mining-cup">
    <h3>üèÜ Data Mining Cup 2023: Analysis of Frankfurt's municipal waste using ML</h3>
          <div class="project-links">
        <a href="https://www.youtube.com/watch?v=aATaEJoIEWI" target="_blank" class="project-link">üé• Highlight Video</a>
        <a href="https://docs.google.com/presentation/d/1tDEmhATAkPBS7Q6yZREYZTyxPrLycnK9/edit?usp=drive_link&ouid=117066328026008436947&rtpof=true&sd=true" target="_blank" class="project-link">üìä Presentation</a>
        <a href="https://drive.google.com/file/d/16qFDwegP5r1TjIkHqprKn0joAgacZZC-/view?usp=drive_link" target="_blank" class="project-link">üìã Application</a>
    </div>
    <p><strong>Description:</strong> In the context of a university project, I used ML to analyze Frankfurt's current state of municipal waste. It included the classification of households regarding residual waste generation based on retail affinity and the forecasting of municipal waste generation. Additionally, targeted campaigns were designed based on the most important attributes of households that generate a high amount of residual waste using Explainable AI. The project was used to participate in the Data Mining Cup 2023, where we won the first place and presented our results in a workshop in Berlin.</p>
    <p><strong>Skills:</strong></p>
    <ul>
      <li><strong>Concepts:</strong> Classification | Forecasting | Explainable AI | Data Analytics | Data Visualization</li>
      <li><strong>Development:</strong> Python | KNIME  </li></li>
      <li><strong>Skills:</strong> Presentation | Communication | Teamwork</li>
      <li><strong>Domain:</strong> Sustainability | Waste Management | Public Service</li>
    </ul>
    <p><strong>Key Learnings:</strong> The classification and usage of explainable AI (Surrogate Linear Model and Decision Tree) revealed that the stronger the retail affinity, the more likely it is a household with high residual waste. The environmental department of Frankfurt proposed an action plan in 2022 to reduce the amount of municipal waste. We used a sample of weighted waste data of 4 years to assess the effectiveness of the action plan and forecast the future development. The result showed that there is still a big gap between reality and plan which highlights the needs for more urgency and actions.</p>
  </div>

  <div class="project-item" id="bert-finetuning">
    <h3>üìä Personal Project: Fine-tuning BERT for Spam Detection</h3>
    <div class="project-links">
      <a href="https://github.com/hoangnghiem17/BERTSpamDetection" target="_blank" class="project-link">üìÅ GitHub</a>
    </div>
    <p><strong>Description:</strong> I fine-tuned a pre-trained BERT model to classify Emails as spam or ham (not spam). The project includes data preprocessing, tokenization with Hugging Face Transformers, model fine-tuning using PyTorch and evaluation based on accuracy and F1 score. To see the performance difference between the pre-trained BERT model and the fine-tuned model, I also evaluated each model version on the test set including the test data, ChatGPT generated Emails and real spam Emails of myself.</p>
    <p><strong>Skills:</strong></p>
    <ul>
      <li><strong>Concepts:</strong> Transfer Learning | NLP | Text Classification | Model Evaluation</li>
      <li><strong>Development:</strong> Python | PyTorch | Hugging Face Transformers | scikit-learn</li>
    </ul>
    <p><strong>Key Learnings:</strong> Fine-tuning a pre-trained model like BERT can improve performance on a specific task. It is essential understand the use case to determine if a fine-tuning approach is reasonable given the required resources. If so, it is critical to select and preprocess qualitative data that will be used for fine-tuning the model. The fine-tuning process must be analyzed with metrics such as training and validation loss to avoid overfitting. At the end, an evaluation must be designed to ensure the fine-tuned model performs well on unknown data.</p>
  </div>
  
<style>
.projects {
  max-width: 800px;
  margin: 0 auto;
  padding: 20px;
}

.projects-intro {
  background: var(--entry);
  padding: 20px;
  border-radius: 8px;
  margin-bottom: 30px;
  border-left: 4px solid var(--accent);
}

.project-item {
  background: var(--entry);
  padding: 25px;
  border-radius: 8px;
  margin-bottom: 25px;
  border: 1px solid var(--border);
  transition: transform 0.2s ease, box-shadow 0.2s ease;
}

.project-item:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
}

.project-item h3 {
  color: var(--accent);
  margin-top: 0;
  margin-bottom: 15px;
  font-size: 1.4em;
}

.project-links {
  margin-bottom: 15px;
}

.project-link {
  display: inline-block;
  background: var(--accent);
  color: white;
  padding: 6px 12px;
  border-radius: 4px;
  text-decoration: none;
  margin-right: 10px;
  margin-bottom: 5px;
  font-size: 0.9em;
  transition: background-color 0.2s ease;
}

.project-link:hover {
  background: var(--accent-hover);
  text-decoration: none;
}

.project-item p {
  margin-bottom: 10px;
  line-height: 1.6;
}

.project-item strong {
  color: var(--accent);
}

.projects h2 {
  color: var(--accent);
  border-bottom: 2px solid var(--accent);
  padding-bottom: 10px;
  margin-top: 40px;
  margin-bottom: 25px;
}

.projects ul {
  list-style: none;
  padding-left: 0;
}

.projects ul li {
  margin-bottom: 8px;
}

.projects ul li a {
  color: var(--accent);
  text-decoration: none;
}

.projects ul li a:hover {
  text-decoration: underline;
}
</style> 